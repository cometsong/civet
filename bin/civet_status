#!/usr/bin/env python

"""
   report on the status of a pipeline.  The pipeline is specified by providing
   the path to its log directory, which is unique for each pipeline
"""

from __future__ import print_function

import argparse
import sys
import os
import inspect
import glob

cmd_folder = os.path.realpath(os.path.abspath(os.path.split(inspect.getfile(inspect.currentframe()))[0]))
lib_folder = os.path.join(cmd_folder, '../lib')
if lib_folder not in sys.path:
     sys.path.insert(0, lib_folder)

import job_runner.torque as batch_system
import job_runner.common
import version


def format_state(state):
    if state == 'R':
        return "Running"
    elif state == 'Q':
        return "Queued (eligible to run)"
    elif state == 'H':
        return "Queued (waiting on dependency)"
    elif state == 'W':
        return "Queued (with delayed start)"
    
    return state


def main():

    version.parse_options()

    parser = argparse.ArgumentParser(prog=os.path.basename(sys.argv[0]))
    parser.add_argument('-r', '--recursive', dest='recursive',
                        action='store_true', help="Run in recursive mode")
    parser.add_argument('--verbose', dest='verbose', action='store_true',
                        help="More verbose output")
    parser.add_argument('-q', '--quiet', dest='quiet', action='store_true',
                        help="Only produce output for failed runs")
    parser.add_argument('dirs', help="Log directory", nargs=argparse.REMAINDER)
    parser.set_defaults(quiet=False)
    parser.set_defaults(verbose=False)
    # change default behavior to recursive, keep option to preserve backwards compatibility
    parser.set_defaults(recursive=True)
    args = parser.parse_args()

    verbose = args.verbose
    quiet = args.quiet
    
    if verbose and quiet:
        print("--quiet (-q) and --verbose options are mutually exclusive\n", file=sys.stderr)
        return 1
    
    dir_list_arg = []

    if len(args.dirs) > 0:
        dir_list_arg = args.dirs
    else:
        dir_list_arg.append('.')

    if args.recursive:
        all_log_dirs = []
        followed_dirs = set()
        for d in dir_list_arg:
            log_dirs = []
            for root, dirs, files in os.walk(d, topdown=True, followlinks=True):
                followed_dirs.add(os.path.realpath(root))
                if job_runner.common.BATCH_ID_LOG in files:
                    log_dirs.append(root)

                # make sure we don't follow any symlinks that point to a dir we've already processed
                for dir in dirs:
                    if os.path.realpath(os.path.join(root,dir)) in followed_dirs:
                        dirs.remove(dir)

            log_dirs.sort()
            all_log_dirs += log_dirs

        if len(all_log_dirs) == 0:
            print("ERROR: no valid log directory found!\n", file=sys.stderr)
            return 1
    else:
        all_log_dirs = dir_list_arg

    jm = batch_system.JobManager()

    for log_dir in all_log_dirs:
    
        log_dir = os.path.abspath(log_dir)
        run_canceled = False
    
        if verbose:
            print("\n\nGetting status for pipeline with log directory at:")
            print("\t{0}".format(log_dir))
    
        if not os.path.isdir(log_dir):
            print("ERROR: {0} does not appear to be a valid pipeline log directory.\n".format(log_dir), file=sys.stderr)
            continue

        # get listing of batch jobs from the pipeline's log directory
        # each line in batch_jobs is [batch_id, job_name, [dependencies]])
        try:
            batch_jobs = job_runner.common.jobs_from_logdir(log_dir)
        except IOError as e:
            print("ERROR: '{0}' does not appear to be a valid pipeline log directory:".format(log_dir), file=sys.stderr)
            print("\t{0}".format(e), file=sys.stderr)
            continue

        if len(batch_jobs) == 0:
            print("{0}: Pipeline submission error".format(log_dir), file=sys.stderr)
            continue
    
        # check to see if the log directory was created with civet_run --no-submit
        if os.path.exists(os.path.join(log_dir, job_runner.common.NO_SUB_FLAG)):
            print(log_dir + ":\n\tThis pipeline was run with --no-submit, so no status is applicable.")
            continue
    
        # check for any *-abort.log -- this will indicate something went wrong with
        # the run
        run_aborted = False

        # this works for older versions of Civet before the abort.log filename
        # was changed to include the name of the job that called abort_pipeline
        if os.path.exists(os.path.join(log_dir, "abort.log")):
            run_aborted = True

        # for newer versions of Civet:
        if glob.glob(os.path.join(log_dir, "*-abort.log")):
            run_aborted = True

        if run_aborted and verbose:
            print("WARNING: Pipeline aborted due to non-zero exit value of at least one job.  Details below.\n")

        if os.path.exists(os.path.join(log_dir, job_runner.common.CANCEL_LOG_FILENAME)):
            run_canceled = True
            cancel_info = dict(line.strip().split('=') for line in open(os.path.join(log_dir, job_runner.common.CANCEL_LOG_FILENAME)))
            if verbose:
                if 'DATESTAMP' in cancel_info:
                    print("PIPELINE WAS CANCELED by user at {}\n".format(cancel_info['DATESTAMP']))
                else:
                    print("PIPELINE WAS CANCELED by user.\n")
    
        complete_jobs_success = 0
        complete_jobs_failure = 0
        canceled_jobs = 0
        running_jobs = 0
        held_jobs = 0
        delayed_jobs = 0
        queued_jobs = 0
        unknown_state = 0
        total_jobs = len(batch_jobs)
    
        for job in batch_jobs:
            if verbose:
                print("\n{0} ({1}):".format(job[1], job[0]))

            if os.path.exists(os.path.join(log_dir, job[1] + job_runner.common.JOB_STATUS_SUFFIX)): 
                status = job_runner.common.get_status_from_file(log_dir, job[1])
                if 'canceled' in status or 'cancelled' in status:
                    if verbose:
                        print("\tJob canceled (state at cancel = {0})".format(format_state(status['state_at_cancel'])))
                    canceled_jobs += 1

                #in some cases a job was running when the pipeline was canceled,
                #but the job is unable to see the cancel.log due to NFS cacheing
                #so it doesn't record the fact that it was canceled. this fixes
                #that
                elif run_canceled and job[0] in cancel_info['RUNNING_JOBS']:
                    if verbose:
                        print("\tJob canceled (state at cancel = Running)")
                    canceled_jobs += 1
                
                elif 'exit_status' in status:
                    if status['exit_status'] == '0':
                        complete_jobs_success += 1
                        if verbose:
                            print("\tFinished=Success")
                    else:
                        complete_jobs_failure += 1
                        if verbose:
                            print("\tFinished=Failure")
                    if verbose:
                        print("\tExit Status={0}".format(status['exit_status']))
                if verbose:
                    if 'walltime' in status:
                        print("\tWalltime={0}".format(status['walltime']))
                    if 'requested_walltime' in status:
                        print("\tWalltime(Requested)={0}".format(status['requested_walltime']))
            else:
                status = jm.query_job(job[0])
                if status:
                    if verbose:
                        print("\tState={0}".format(format_state(status.state)))
                    if status.state == 'R' or status.state == 'C':
                        if status.state == 'R':
                            running_jobs += 1
                        else:
                            # if we got here the job is in state "C" but no 
                            # job_name-status.txt file was created.  Job must have 
                            # crashed or was canceled...
                            if status.exit_status == "0":
                                #This shouldn't happen... if there isn't
                                #a job_name-status.txt the exit status should be non-zero
                                #maybe we should print a warning here about the
                                #unexpected state
                                complete_jobs_success += 1
                                if verbose:
                                    print("\tFinished=Success")
                            else:
                                complete_jobs_failure += 1
                                if verbose:
                                    print("\tFinished=Failure")
                            if verbose:
                                print("\tExit Status={0}".format(status.exit_status))
                        if verbose:
                            print("\tWalltime={0}".format(status.walltime))
                            print("\tWalltime(Requested)={0}".format(status.requested_walltime))
                    elif status.state == 'H':
                        held_jobs += 1
                        if verbose:
                            print("\tWalltime(Requested)={0}".format(status.requested_walltime))
                            print("\tDepends on {0}".format(job[2]))
                    elif status.state == 'Q':
                        queued_jobs += 1
                        if verbose:
                            print("\tWalltime(Requested)={0}".format(status.requested_walltime))
                    elif status.state == 'W':
                        delayed_jobs += 1
                        if verbose:
                            print("\tWalltime(Requested)={0}".format(status.requested_walltime))

                else:
                    if verbose:
                        if run_aborted:
                            print("\tpbs_server returned no information for job {0} (job aborted)".format(job[0]))
                        elif run_canceled:
                            print("\tpbs_server returned no information for job {0} (pipeline canceled by user)".format(job[0]))
                        else:
                            print("\tWARNING=pbs_server returned no information for job {0}.  Job may have been deleted or it may have crashed.".format(job[0]))
                    unknown_state += 1

        if complete_jobs_failure:
            summary_status = "FAILED"
        elif run_canceled:
            summary_status = "CANCELED"
        elif complete_jobs_success == total_jobs:
            summary_status = "completed successfully"
        elif unknown_state:
            summary_status = "TERMINATED (reason unknown)"
        else:
            summary_status = "running"
         
        if verbose:
            print("\nSummary:")
        elif not quiet or summary_status == 'FAILED' or summary_status == 'CANCELED' or 'TERMINATED' in summary_status:
            print("{0}: {1}".format(log_dir, summary_status))
            
        if verbose or (not quiet and complete_jobs_success != total_jobs):
            print("\tTotal Pipeline Jobs: {0}".format(total_jobs))
            print("\t\tCompleted Jobs (success): {0}".format(complete_jobs_success))
            print("\t\tCompleted Jobs (with error): {0}".format(complete_jobs_failure))
            print("\t\tRunning Jobs: {0}".format(running_jobs))
            print("\t\tPending Jobs (waiting for compute resources): {0}".format(queued_jobs))
            print("\t\tPending Jobs (waiting on dependency): {0}".format(held_jobs))
            if delayed_jobs:
                print("\t\tPending Jobs (delayed start): {0}".format(delayed_jobs))
            if canceled_jobs:
                print("\t\tCanceled Jobs: {0}".format(canceled_jobs))
            if unknown_state:
                #now that a status.txt file should get created for any job that
                #runs, if we have any "unknown" jobs then it means they were
                #probably deleted (qdel), other possibility is there was a
                #node crash that took out the job
                print("\t\tDeleted Jobs: {0}".format(unknown_state))
        if verbose:
            print("\n\n")

if __name__ == '__main__':
    main()
