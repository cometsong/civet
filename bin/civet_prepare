#!/usr/bin/env python

# Copyright 2017 The Jackson Laboratory
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

#civet pipeline driver program

from __future__ import print_function

import argparse
import sys
import inspect
import os
import logging

cmd_folder = os.path.realpath(os.path.abspath(os.path.split(inspect.getfile(inspect.currentframe()))[0]))
lib_folder = os.path.join(cmd_folder, '../lib')
if lib_folder not in sys.path:
    sys.path.insert(0, lib_folder)
import civet_exceptions
import pipeline_parse as PL
import version
import utilities

from managed_batch.model.session import Session
from managed_batch.model.job import Job
from managed_batch.model.pipeline import Pipeline

from managed_batch.controller.utilities import initialize_model, init_statuses, get_file_info, init_file_info


def main():

    utilities.cleanup_command_line()

    version.parse_options()
    
    parser = argparse.ArgumentParser()

    parser.add_argument('-q', '--queue', default=None,
                        help="submission queue [default = TORQUE default]")
    parser.add_argument('-o', '--option-file', dest='option_file',
                        default=None, help="option override file")
    parser.add_argument('-t', '--keep-temp', dest='keep_temp',
                        action='store_true',
                        help="Don't delete temporary pipeline files")
    parser.add_argument('-f', '--force-conditional', dest='force_conditional',
                        action='store_true',
                        help="Force conditional steps to run")
    parser.add_argument('-e', '--email-address', dest='email_address',
                        default=None,
                        help="email address for notifications, defaults to user. Can be a comma delimited list of addresses.")
    parser.add_argument('--error-email-address', dest='error_email_address',
                        default=None, help="email address for error emails, defaults to '--email-address' value")
    parser.add_argument('--walltime-multiplier', dest='walltime_multiplier',
                        type=float, default=None,
                        help="optional walltime multiplier to be applied to every job's walltime")
    parser.add_argument('--write-file-summary', action='store_true',
                        help="write a file containing information about Civet "
                             "file objects used in this pipeline into the log "
                             "directory")
    parser.add_argument('--task-db', required=True,
                        help='filename where civet_prepare will store the tasks'
                             '. If the file exists, civet_prepare will '
                             'add new tasks to the file.')
    parser.add_argument('--log-level', '-l',
                        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                        default='ERROR',
                        help="Minimum logging level to display. [%(default)s]")

    parser.add_argument('pipeline', help="pipeline XML definition", nargs=1)
    parser.add_argument('pipeline_args', help="pipeline arguments",
                        nargs=argparse.REMAINDER)
    parser.set_defaults(keep_temp=False)
    parser.set_defaults(force_conditional=False)
    args = parser.parse_args()

    logging.basicConfig(level=getattr(logging, args.log_level.upper()))

    logging.debug("Parsed arguments: {}".format(args))

    try:
        PL._parse_XML(args.pipeline[0], args.pipeline_args,
                      skip_validation=True,
                      queue=args.queue,
                      search_path=os.environ.get('CIVET_PATH'),
                      user_override_file=args.option_file,
                      keep_temp=args.keep_temp,
                      force_conditional_steps=args.force_conditional,
                      email_address=args.email_address,
                      error_email_address=args.error_email_address,
                      walltime_multiplier=args.walltime_multiplier,
                      write_pipeline_files=args.write_file_summary)
    except civet_exceptions.ParseError as e:
        logging.exception("Error parsing XML:  {}\n".format(e))
        sys.exit("\nError parsing XML:  {}\n".format(e))
    except civet_exceptions.MissingFile as e:
        logging.exception("Pipeline Error: {}".format(e))
        print("\nPipeline Error: {}".format(e), "\n", file=sys.stderr)
        sys.exit(2)

    append_mode = os.path.exists(args.task_db)

    try:
        Session.session = initialize_model(args.task_db)
    except Exception as e:
        logging.exception("Error opening task database: {}".format(e.message))
        print("Error opening task database: {}".format(e.message), file=sys.stderr)
        sys.exit(3)

    if not append_mode:
        logging.debug("Not in append mode. Initializing.")
        init_statuses()
        init_file_info()
    else:
        # make sure the task file hasn't already been submitted
        logging.debug("In append mode.")
        file_info = get_file_info()
        if file_info.started:
            logging.error("Unable to add tasks to task file {}\n"
                  "\tTask file has already been submitted.".format(args.task_db))
            print("\tUnable to add tasks to task file {}\n"
                  "\t\tTask file has already been submitted.".format(args.task_db),
                  file=sys.stderr)
            sys.exit(4)

    pipeline = Pipeline(PL.name, PL.log_dir)
    logging.debug("Pipeline is: {}".format(pipeline))

    task_list = PL.prepare_managed_tasks()
    logging.debug("Task list is: {}".format(task_list))

    # we need to be able to translate the dependencies as stored in the task
    # list (list of other task names that a particular task depends on)
    # into a list of Job object references that have already been added to the
    # session. We will build up a dictionary of task['name'] : Job as we
    # insert them
    deps_to_job = {}
    print("  Inserting tasks into {}".format(args.task_db))
    logging.info("Inserting tasks into {}".format(args.task_db))
    try:
        for task in task_list:
            print("    -> {}".format(task['name']))
            try:
                dependencies = [deps_to_job[d] for d in task['dependencies']]
            except KeyError as e:
                logging.exception("Key error processing dependencies")
                msg = "Task {} depends on a task that hasn't been been processed ({}). Check your Pipeline XML".format(task['name'], d)
                raise Exception(msg)
            job = Job(pipeline, task['name'], task['threads'],
                      task['stdout_path'], task['stderr_path'],
                      task['script_path'], task['epilogue_path'],
                      task['mem'], task['email_list'], task['mail_options'],
                      task['batch_env'], dependencies, task['queue'],
                      task['walltime'])

            deps_to_job[task['name']] = job
            logging.debug("Adding job {} to session".format(job))
            Session.add(job)
    except Exception as e:
        logging.exception("Error inserting tasks into database")
        print("Error inserting tasks into database: " + e.message, file=sys.stderr)
        sys.exit(4)

    # only commit the session if we were able to add all the jobs to the session
    # without catching an Exception
    Session.commit()

    logging.info("  {} tasks have been inserted into task file {}; (log dir: {})".format(len(task_list), args.task_db, PL.log_dir))
    print("  {} tasks have been inserted into task file {}\n".format(len(task_list), args.task_db))
    print("    pipeline log directory: " + PL.log_dir + "\n")

    print("    Pipeline can now be executed in managed mode with the 'civet_start_managed' command")
    print("        civet_start_managed {}:".format(args.task_db))
    print("        See civet_start_managed --help for program options")

if __name__ == "__main__":
    main()
